# Response Letter

> Qirui Guo, Kun Qian, Zhigui Wu

+ >  从应用以及结果可视化的角度，我们可能希望聚类、动力学分析以及UMAP的结果比较一致，即在UMAP上邻近的cluster在动力学分析中的pseudotime（latent time）也比较接近。一般的方法中，做降维、聚类、动力学分析（如RNA  velocity，cellrank等）用的都是相同的kNN，因此结果可能一致性较好。在你们的方法中，聚类与轨迹分析分别采用了kNN的不同子图，因此在一个UMAP中，你们的方法可能无法对聚类的结果与轨迹推断的结果同时有比较好的展示效果（如果用聚类的KNN构建UMAP，轨迹分析的结果可能会比较乱；用轨迹推断的KNN构建UMAP，cluster可能会比较乱）。是否有可能修剪出一个折中的子图，聚类的效果与轨迹推断的效果都比修剪前的kNN好？

  + 现在尝试的几个数据集中不太能找到比较合适的能够使得聚类的效果与轨迹推断的效果都比修剪前的kNN好的例子, 我们认为这应当是和下游任务对于子图信息的需求不同造成的. 我们只能做到对于给定任务删掉一些边之后保持下游结果的准确性,或者有所改善. You can't make an omelette without breaking eggs~ 

+ >  Cellrank中似乎也有在KNN上进行删边的步骤，如果删边的目的一致，能否依此对你们删除的边进行某种验证？

  + 现在其实有很多方法基于去噪的考虑加入了删边的方法, 这些方法各有利弊, 我们只是提供一种基于几何角度删边的视角. 就Cell rank而言

+ > 所提出的图上的这样的一种指标，有办法从理论上说明一些等价性吗，比如说用这种指标做出来的东西，在一些假设下，我们可以证明这是有某种保流形的性质的？

  + 我们的方法不是为了在图上构建一个等价切空间, 而是通过对于边曲率的筛选凸显子图中我们关心连接关系的边. 例如在聚类中我们保留相连节点邻域变化不大的边, 在轨迹推断中我们保留相连节点邻域变化较大的边. 继而起到有限的边给出较好结果的效果

+ > + 这种指标是一种裁剪的方法，也有其他给边权重之后再来裁剪的方法，比如说选用不同指标做裁剪后会有区别吗，可以做一些benchmark的比较吗，比如可以说明这种方法确实某种情形下会更好，或者可以更好的保持一些流形结构。
  >
  > + 同样的比如不同指标的裁剪方法使用第二个神经网络得出的结果会有什么不一样吗？如何说明基于类Ricc流这种指标方法的优越性呢？

  + 这个确实有很多指标, 但是时间所限我们没有时间测试了

+ > + 第二个方法里面神经网络的训练泛化性如何，训练是否只是依赖图的拓扑结构，和结点的数据会有关系吗，比如会不会换个数据，网络就要重新训练了？
  >
  > + 现在这个方法的计算成本还是有点大的，无论是第一个过程还是第二个训练网络，如何在效果和速度之间平衡trade-off?

  + 这是目前方法的一个问题, 极端情况下甚至会出现剪边时间大于下游节省的时间的情况, 我们之后会探索不同方法改进

+ > 我读过STAGATE的工作，就是在图神经网络里面有剪枝这个操作。与流形距离有关的，我见过MIOFLOW，或者是OT里面都可以引入所谓保持某种测地线距离，可能也是这里面所说的黎曼度量，还有CycleGAN等一些流形嵌入方法，供参考。

  + 好的, 感谢同学的建议

+ > KNN现有的很大问题就是超参数的存在。为了克服这个问题，一般的思路是构建一个算法来自动选择最佳的k。但据我的了解，你们的思路是切边。这样在算法上会带来哪些好处？此外，如果这个问题通过你们的方法切实解决了，那么切边后的KNN图理论上不应该对k特别敏感，你们是否有测试过这一点？

  + 我们的方法不是为了做自适应, 而是希望通过裁减边达到省力好用的效果. 目前版本的算法中其实引入了一个新的超参数, 即从现有k要裁到子图的k. 但是我们之后期望通过统计方法获取有统计学意义的节点上边的曲率分布, 继而实现真正意义上的自适应操作. 

+ > 现存很多不依赖预先定义超参数的聚类方法，可以尝试在不同数据集上做benchmarking来评估算法的可靠性。

  + 没时间尝试了, 抱歉

+ > 汇报中提到使用curvature对knn中的连边进行优化，是否能对curvature优化knn的原理进行直观解释。另外我们未能完全理解曲率对于在流形上本不相邻的两点之间如何进行定义，以及在计算上是否仅通过所考察的两点的坐标就能导出对应曲率；如果这一曲率的计算过程中需要使用连边的两点外其他点的坐标信息，应当如何理解这一曲率有效的反应了连边本身的性质而没有收到其他邻居的过度影响？

  + 我们在报告Fig1以及Methods中加入了对于方法用到曲率的简介

+ > 在使用机器学习方法从k=5出发学习更大邻居数的连边情况这一优化方法中，在训练时如何在更多邻居数的情况下对一条连边是否是好的连边进行标注，即labeling的具体依据是什么。

  + 

+ > 是否能够设置定量的评判指标来对优化前后knn的效果进行评估。

  + 现在的指标确实比较定性, 我们会在之后尝试设计足够直观的定量指标

+ > 该方法在应用上可不可以多加一些例子，例如本次课展示的是免疫细胞的分化轨迹问题，这是一种轨迹问题，还有另一种轨迹是发育轨迹，可以展示一下该方法描绘的轨迹与真实的发育轨迹重合度怎样？

  + 我们没有做真实数据, 但是尝试了发育路径与分岔路径的模拟数据, 两种数据中通过最大曲率裁边我们的方法产生的子图都能在较少的边情况下实现和k较大图上类似的效果.

+ > 该方法是基于曲率优化了KNN方法，该方法理论上会有助于基于KNN的算法，比如不同数据集的整合（基于Anchor的方法），能否简单展示一下优化前后数据集整合效果如何？

  + 不同数据集整合对于KNN信息的要求可能和聚类与轨迹推断不同, 我们暂时没有考虑

+ > 感觉您或许可以考虑在后续成文的final report里加上一些示意图，就相当于类似数学直觉的示意图让非数学与统计背景的人也能比较直观理解这个算法做了什么。

  + 我们在报告Fig1以及Methods中加入了对于方法用到曲率的简介

+ > 或许您可以考虑一下将代码实现进行封装和开源，方便大家在自己的具体应用场景里进行测试。

  + 我们将代码同`scanpy.pp.neighbors`进行了整合, 现在可以drop in替换了, 针对曲率计算我们还设计了GPU加速模块, 具体教程在github repo中, 欢迎体验.